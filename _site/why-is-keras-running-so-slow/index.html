<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Why is Keras Running So Slow?</title>
  <meta name="description" content="">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://www.chioka.in/why-is-keras-running-so-slow/">
  <link rel="alternate" type="application/rss+xml" title="Garbled Notes" href="http://www.chioka.in/feed.xml" />

  <link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link href='http://fonts.googleapis.com/css?family=PT+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,700' rel='stylesheet' type='text/css'>
</head>


  <body>

    <div class="site-header">

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <i class="fa fa-navicon fa-lg"></i>
      </a>

      <div class="trigger">
          <a class="page-link" href="/">Home</a>
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>


</div>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
     <h1 class="post-title">Why is Keras Running So Slow?</h1>
     <p class="post-meta">Posted on Dec 5, 2015 â€¢ lo</p>
  </header>

  <article class="post-content">
    <p><a href="http://www.chioka.in/wp-content/uploads/2015/12/meme.jpg"><img class="aligncenter size-full wp-image-640" src="http://www.chioka.in/wp-content/uploads/2015/12/meme.jpg" alt="meme" width="512" height="340" /></a></p>

<p>More notes for myself&#8230; so it may not be helpful for you who bumped into here. ðŸ˜‰</p>

<h1>Why This Article?</h1>

<p><a href="http://www.chioka.in/how-to-setup-theano-to-run-on-gpu-on-ubuntu-14-04-with-nvidia-geforce-gtx-780/" target="_blank">Setting Theano correctly</a>Â <strong>is not enough</strong> to ensureÂ you can run deep learning software correctly. In our case, it will be Keras, and it can slow to a crawl ifÂ not setup properly.</p>

<p>Again, there could be many causes but I try to outline a clean step what I did, theÂ performance I run aÂ good setup, so you can compare. Hopefully you can glean some places where you did wrong.</p>

<h1>Specifications</h1>

<p>MyÂ server hasÂ the following specifications finished running the steps outlined <a href="http://www.chioka.in/how-to-setup-theano-to-run-on-gpu-on-ubuntu-14-04-with-nvidia-geforce-gtx-780/" target="_blank">here</a>.</p>

<ul>
<li>OS: Ubuntu 14.04 LTS, X64</li>
<li>GPU:Â NvidiaÂ Geforce GTX 780</li>
<li>Ubuntu 14.04 LTS</li>
<li>CUDA 7.5</li>
<li>Theano 0.7.0</li>
<li>Numpy 1.8.2</li>
<li>Kera 0.2.0</li>
<li>Scipy 0.13.3</li>
<li>NVIDIA-SMI 352.39</li>
<li>Graphics Driver Version: 352.39</li>
</ul>

<h1>Instructions</h1>

<ol>
<li>Make sure your TheanoÂ configuration file, located at ~/.theanorc, is correct:</li>
</ol>

<pre>$ cat ~/.theanorc
[global]
floatX = float32
device = gpu
optimizer = fast_run

[lib]
cnmem = 0.8

[nvcc]
fastmath = True

[blas]
ldflags = -llapack -lblas</pre>

Use this to see your Theano settings in runtimeÂ and make sure it matches what you have above. Only some output is shown since it is very long:

<pre>$ python -c <span class="s1">'import theano; print theano.config'
</span>
Using gpu device 0: GeForce GTX 780 (CNMeM is enabled)
floatX (('float64', 'float32', 'float16')) 
 Doc: Default floating-point precision for python casts.

Note: float16 support is experimental, use at your own risk.
 Value: float32

warn_float64 (('ignore', 'warn', 'raise', 'pdb')) 
 Doc: Do an action when a tensor variable with float64 dtype is created. They can't be run on the GPU with the current(old) gpu back-end and are slow with gamer GPUs.
 Value: ignore

...
...
...

</pre>

<ol>
<li>Install Theano bleeding edge (0.7.0), sinceÂ the Keras examples needs &#8216;relu&#8217;.</li>
</ol>

<pre>pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git</pre>

<p>Detailed instructions <a href="http://deeplearning.net/software/theano/install.html#bleeding-edge-install-instructions">here</a>.</p>

<p>3.Â Get Keras source and run the mnist_mlp.py to checkÂ the performance.</p>

<pre>$ git cloneÂ https://github.com/fchollet/keras.git
Cloning into 'keras'...
remote: Counting objects: 6572, done.
remote: Total 6572 (delta 0), reused 0 (delta 0), pack-reused 6572
Receiving objects: 100% (6572/6572), 1.29 MiB | 894.00 KiB/s, done.
Resolving deltas: 100% (4571/4571), done.
Checking connectivity... done.</pre>

<pre>$ cd keras/examples
$ $ time python mnist_mlp.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 780 (CNMeM is enabled)
60000 train samples
10000 test samples
Train on 60000 samples, validate on 10000 samples
Epoch 1/20
0s - loss: 0.2805 - acc: 0.9148 - val_loss: 0.1165 - val_acc: 0.9636
Epoch 2/20
0s - loss: 0.1151 - acc: 0.9651 - val_loss: 0.0960 - val_acc: 0.9685
Epoch 3/20
0s - loss: 0.0800 - acc: 0.9754 - val_loss: 0.0670 - val_acc: 0.9787
Epoch 4/20
0s - loss: 0.0624 - acc: 0.9806 - val_loss: 0.0703 - val_acc: 0.9775
Epoch 5/20
0s - loss: 0.0506 - acc: 0.9837 - val_loss: 0.0622 - val_acc: 0.9795
Epoch 6/20
0s - loss: 0.0414 - acc: 0.9867 - val_loss: 0.0641 - val_acc: 0.9803
Epoch 7/20
0s - loss: 0.0347 - acc: 0.9892 - val_loss: 0.0665 - val_acc: 0.9802
Epoch 8/20
0s - loss: 0.0295 - acc: 0.9906 - val_loss: 0.0769 - val_acc: 0.9789
Epoch 9/20
0s - loss: 0.0258 - acc: 0.9915 - val_loss: 0.0586 - val_acc: 0.9830
Epoch 10/20
0s - loss: 0.0215 - acc: 0.9928 - val_loss: 0.0577 - val_acc: 0.9841
Epoch 11/20
1s - loss: 0.0197 - acc: 0.9932 - val_loss: 0.0605 - val_acc: 0.9844
Epoch 12/20
0s - loss: 0.0180 - acc: 0.9940 - val_loss: 0.0560 - val_acc: 0.9863
Epoch 13/20
0s - loss: 0.0163 - acc: 0.9945 - val_loss: 0.0630 - val_acc: 0.9838
Epoch 14/20
0s - loss: 0.0136 - acc: 0.9956 - val_loss: 0.0608 - val_acc: 0.9857
Epoch 15/20
0s - loss: 0.0130 - acc: 0.9958 - val_loss: 0.0616 - val_acc: 0.9838
Epoch 16/20
0s - loss: 0.0114 - acc: 0.9960 - val_loss: 0.0584 - val_acc: 0.9854
Epoch 17/20
0s - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0672 - val_acc: 0.9849
Epoch 18/20
0s - loss: 0.0106 - acc: 0.9964 - val_loss: 0.0678 - val_acc: 0.9846
Epoch 19/20
0s - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0749 - val_acc: 0.9835
Epoch 20/20
0s - loss: 0.0085 - acc: 0.9971 - val_loss: 0.0685 - val_acc: 0.9843
Test score: 0.0685058810504
Test accuracy: 0.9843

<span style="color: #00ff00;"><strong>real 0m24.560s</strong></span>
user 0m23.216s
sys 0m1.328s


</pre>

<p>As you can see,Â the whole run takes only 25 seconds, and itÂ may take even less or maybe 2 minutes for you. Anything longer than that looks strange and you should inspect.</p>

<ol>
<li>Install <a href="https://developer.nvidia.com/cuDNN" target="_blank">CuDNN</a> if you are using ConvNet.Â The basic implementations of convolution in Theano are significantly slower.</li>
</ol>

<p>Downloading CuDNN is problematic, because you have to register an account on Nvidia and wait for hours or days for manual approval. Someone uploaded a version of CuDNN 6.5 for download on Google Drive <a href="http://deeplearning.net/software/theano/library/sandbox/cuda/dnn.html" target="_blank">here</a> if you don&#8217;t want to wait.</p>

<p>Once you have it, just unzip theÂ tgz file.</p>

<pre>$ tar zxvf cudnn-6.5-linux-x64-v2.tgz
$ cd cudnn-6.5-linux-x64-v2
$ ls
cudnn.h CUDNN_License.pdf INSTALL.txt libcudnn.so libcudnn.so.6.5 libcudnn.so.6.5.48 libcudnn_static.a
$ pwd
/home/echio/src/cudnn-6.5-linux-x64-v2</pre>

<ol>
<li>Make sure your CUDA and CuDNN are bothÂ accessible to Theano.</li>
</ol>

<p>To check if your Theano is using CuDNN.Â Run this Python code below:</p>
<figure class="highlight"><pre><code class="language-text" data-lang="text"># Run this python code
from theano.sandbox.cuda.dnn import *
print(dnn_available())
print(dnn_available.msg)
</code></pre></figure>
<p>I alsoÂ captured the environment variables, replace echio with your username:</p>

<pre>$ echo $CPATH

$ echo $LD_LIBRARY_PATH
/usr/local/cuda-7.5/lib64:
$ echo $LIBRARY_PATH
/usr/local/cuda-7.5/lib64:
$ python
Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; from theano.sandbox.cuda.dnn import *
Using gpu device 0: GeForce GTX 780 (CNMeM is enabled)
&gt;&gt;&gt; print(dnn_available())
False
&gt;&gt;&gt; print(dnn_available.msg)
<strong>Theano can not compile with cuDNN. We got this error:</strong>
<strong>/tmp/try_flags_sbkMKM.c:5:19: fatal error: cudnn.h: No such file or directory</strong>
 #include &lt;cudnn.h&gt;
 ^
compilation terminated.</pre>

<p><a href="https://goo.gl/bTW22Q" target="_blank">Googling the error message</a>Â doesn&#8217;t help too much.</p>

<p>You need to add the location of the 3. into CPATH, LD_LIBRARY_PATH and LIBRARY_PATH. This is what myÂ .bashrc looks like this (replace echio with your username):</p>

<pre># ~/.bashrc
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-7.5/lib64:/home/echio/src/cudnn-6.5-linux-x64-v2:
export LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-7.5/lib64:/home/echio/src/cudnn-6.5-linux-x64-v2:
export CPATH=$CPATH:/home/echio/src/cudnn-6.5-linux-x64-v2:
export PATH=$PATH:/usr/local/cuda-7.5/bin</pre>

<p>If you instead see this error message:</p>

<pre>ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.7.5: cannot open shared object file: No such file or directory</pre>

<p>You probably didn&#8217;t have CUDA environment variables setup properly. See the above ~/.bashrc lines for correct setup.</p>

<ol>
<li><p>Run this codeÂ again.</p>

<h1>Run this python code</h1>

<p>from theano.sandbox.cuda.dnn import *
print(dnn<em>available())
print(dnn</em>available.msg)</p></li>
</ol>

<p>You should see below when executed in a Python REPL.</p>

<pre>&gt;&gt;&gt; from theano.sandbox.cuda.dnn import *
Using gpu device 0: GeForce GTX 780 (CNMeM is enabled)
&gt;&gt;&gt; print(dnn_available())
True
&gt;&gt;&gt; print(dnn_available.msg)
None</pre>

<p>This is good! Re-run your Keras code and hopefully it will be fast this time&#8230;</p>

<h1>Conclusion</h1>

<p>ThisÂ may or may not solve your problem, but it certainly solved some of my problems. You will probably have to learn to debug things a bit to figure out how to get it to run well.</p>

<h4>References</h4>

<ul>
<li><a href="http://deeplearning.net/software/theano/library/config.html" target="_blank"><a href="http://deeplearning.net/software/theano/library/config.html">http://deeplearning.net/software/theano/library/config.html</a></a></li>
<li><a href="http://deeplearning.net/software/theano/library/sandbox/cuda/dnn.html" target="_blank"><a href="http://deeplearning.net/software/theano/library/sandbox/cuda/dnn.html">http://deeplearning.net/software/theano/library/sandbox/cuda/dnn.html</a></a></li>
<li><a href="https://groups.google.com/forum/#!topic/keras-users/EAbpVHJBvGQ" target="_blank"><a href="https://groups.google.com/forum/#!topic/keras-users/EAbpVHJBvGQ">https://groups.google.com/forum/#!topic/keras-users/EAbpVHJBvGQ</a></a></li>
</ul>

<p>&nbsp;</p>

  </article>

  <div align="center">
  	<a href="#">
  	<i class="fa fa-arrow-circle-up fa-2x"></i>
  	</a>
  </div>

  <div id="disqus_thread"></div>
  <script>
      /**
       *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
       *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
       */
      /*
      var disqus_config = function () {
          this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
          this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
      };
      */
      (function() {  // DON'T EDIT BELOW THIS LINE
          var d = document, s = d.createElement('script');
          
          s.src = '//log0.disqus.com/embed.js';
          
          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

</div>

      </div>
    </div>

    <div class="footer center">

  Copyright &copy; <a href=http://diezcami.github.io target="_blank">Camille Diez</a> 2015<BR />
  Powered by <a href=http://jekyllrb.com target="_blank">Jekyll</a>

</div>


  </body>
</html>
